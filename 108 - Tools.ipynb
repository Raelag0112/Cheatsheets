{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                 transforms.RandomHorizontalFlip(),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean, std)]),\n",
    "    \n",
    "    'val' : transforms.Compose([transforms.Resize(256),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean, std)]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ants', 'bees']\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "data_dir = 'hymenoptera_data'\n",
    "sets = ['train', 'val']\n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                         data_transforms[x])\n",
    "                 for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict)\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs-1}')\n",
    "        print('_'*10)\n",
    "        \n",
    "        # each epoch has a training and a validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() # set model to training mode\n",
    "            else:\n",
    "                model.eval() # set model to evaluate mode\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            # iterate over data\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed//60:.0f}m {time_elapsed%60:.0f}s')\n",
    "    print(f'Best val acc: {best_acc:.4f}')\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# scheduler\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "__________\n",
      "train Loss: 0.6962 Acc: 0.5325\n",
      "val Loss: 0.5647 Acc: 0.7320\n",
      "\n",
      "Epoch 1/1\n",
      "__________\n",
      "train Loss: 0.5584 Acc: 0.7317\n",
      "val Loss: 0.4156 Acc: 0.8562\n",
      "\n",
      "Training complete in 1m 47s\n",
      "Best val acc: 0.8562\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "__________\n",
      "train Loss: 0.6283 Acc: 0.6626\n",
      "val Loss: 0.4624 Acc: 0.8105\n",
      "\n",
      "Epoch 1/1\n",
      "__________\n",
      "train Loss: 0.5126 Acc: 0.7846\n",
      "val Loss: 0.3850 Acc: 0.8954\n",
      "\n",
      "Training complete in 1m 51s\n",
      "Best val acc: 0.8954\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.required_grad = False\n",
    "    \n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# scheduler\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tb-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12104), started 1:09:39 ago. (Use '!kill 12104' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-566096e159080f33\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-566096e159080f33\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='.', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='.', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(train_loader)\n",
    "example_data, example_targets = examples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')\n",
    "#plt.show()\n",
    "img_grid = torchvision.utils.make_grid(example_data)\n",
    "writer.add_image('mnist_images', img_grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, example_data.reshape(-1, 28*28))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 / 1, step 100/938, loss=0.1248\n",
      "epoch 1 / 1, step 200/938, loss=0.1127\n",
      "epoch 1 / 1, step 300/938, loss=0.1442\n",
      "epoch 1 / 1, step 400/938, loss=0.0926\n",
      "epoch 1 / 1, step 500/938, loss=0.2043\n",
      "epoch 1 / 1, step 600/938, loss=0.0496\n",
      "epoch 1 / 1, step 700/938, loss=0.0548\n",
      "epoch 1 / 1, step 800/938, loss=0.0637\n",
      "epoch 1 / 1, step 900/938, loss=0.0808\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "running_loss = 0.0\n",
    "running_correct = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # 100, 1, 28, 28\n",
    "        # 100, 784\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        running_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss={loss.item():.4f}')\n",
    "            writer.add_scalar('train loss', running_loss/100, epoch*n_total_steps + i)\n",
    "            writer.add_scalar('acc', running_correct/100, epoch*n_total_steps + i)\n",
    "            running_loss = 0.0\n",
    "            running_correct = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 97.33\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "labels = []\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels1 in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels1 = labels1.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # value, index\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels1.shape[0]\n",
    "        n_correct += (predicted == labels1).sum().item()\n",
    "        \n",
    "        class_predictions = [F.softmax(output, dim=0) for output in outputs]\n",
    "        preds.append(class_predictions)\n",
    "        labels.append(predicted)\n",
    "    \n",
    "    preds = torch.cat([torch.stack(batch) for batch in preds])\n",
    "    labels = torch.cat(labels) \n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'accuracy = {acc}')\n",
    "    \n",
    "    classes = range(10)\n",
    "    for i in classes:\n",
    "        labels_i = labels == i\n",
    "        preds_i = preds[:, i]\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(arg, PATH)\n",
    "# torch.load(PATH)\n",
    "# model.load_state_dict(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_input_features=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[ 0.2013, -0.3494, -0.0531, -0.3253,  0.3918, -0.3695]])), ('linear.bias', tensor([0.1933]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = 'model.pth'\n",
    "torch.save(model.state_dict(), FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear): Linear(in_features=6, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = Model(n_input_features=6)\n",
    "loaded_model.load_state_dict(torch.load(FILE))\n",
    "loaded_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[ 0.2013, -0.3494, -0.0531, -0.3253,  0.3918, -0.3695]])), ('linear.bias', tensor([0.1933]))])\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'epoch': 90,\n",
    "    'model_state': model.state_dict(),\n",
    "    'optim_state': optimizer.state_dict()\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_checkpoint = torch.load('checkpoint.pth')\n",
    "epoch = loaded_checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_input_features=6)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optim_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1]}]}\n"
     ]
    }
   ],
   "source": [
    "print(optimizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndevice = torch.device('cuda')\\nmodel.to(device)\\ntorch.save(model.state_dict(), PATH)\\n\\ndevice = torch.device('cpu')\\nmodel = Model(*args, **kwargs)\\nmodel.load_state_dict(torch.load(PATH, map_location=device))\\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save on gpu, load on cpu\n",
    "\"\"\"\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
