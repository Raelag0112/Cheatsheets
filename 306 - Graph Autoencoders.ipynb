{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47b0425-a468-477b-a9bd-41050382b61a",
   "metadata": {},
   "source": [
    "### Outline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a911c7-9594-4cd3-a00b-88c353db8022",
   "metadata": {},
   "source": [
    "Graph AutoEncoders GAE &  \n",
    "Variational Graph Autoencoders VGAE    \n",
    "\n",
    "[paper](https://arxiv.org/pdf/1611.07308.pdf)  \n",
    "[code](https://github.com/rusty1s/pytorch_geometric/blob/master/examples/autoencoder.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87ff55d-35bd-4b9c-896a-22137671a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9a186-4fda-4acb-9132-345a5d2b9189",
   "metadata": {},
   "source": [
    "# Graph AutoEncoder GAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508ee009-5946-40f1-80dd-ce8893799b6f",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7336d26-5ce7-43d2-8bfe-b6cd5447c098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid(\"\\..\", \"CiteSeer\", transform=T.NormalizeFeatures())\n",
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df5035c-a995-4564-8e44-c774c8441483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data.train_mask = data.val_mask = data.test_mask = None\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0362c0f-0c02-41d9-b003-d8b932146321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Travail\\anaconda3\\envs\\pyg\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "data = train_test_split_edges(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d0215e6-f25f-487a-8e0b-1cd3530b592e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], y=[3327], val_pos_edge_index=[2, 227], test_pos_edge_index=[2, 455], train_pos_edge_index=[2, 7740], train_neg_adj_mask=[3327, 3327], val_neg_edge_index=[2, 227], test_neg_edge_index=[2, 455])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24369d6d-b841-417a-b036-fab50df51961",
   "metadata": {},
   "source": [
    "### Define the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e66a2f-499d-42f0-acd8-ed9fecc69152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv2 = GCNConv(2 * out_channels, out_channels, cached=True) # cached only for transductive learning\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9951747-3567-41b1-bb3b-2ce6f2d54260",
   "metadata": {},
   "source": [
    "### Define the Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2424ba-cbee-4947-bfaf-f77edd8d8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d9b7672-178f-4554-a99f-9914b66f2128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 2\n",
    "num_features = dataset.num_features\n",
    "epochs = 100\n",
    "\n",
    "# model\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "\n",
    "# move to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "945fd388-7ddf-4c3e-9555-81f8b1d1e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    #if args.variational:\n",
    "    #   loss = loss + (1 / data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8afc531-d0ad-476b-b8b5-c587781472aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.6390, AP: 0.6783\n",
      "Epoch: 002, AUC: 0.6467, AP: 0.6879\n",
      "Epoch: 003, AUC: 0.6395, AP: 0.6834\n",
      "Epoch: 004, AUC: 0.6372, AP: 0.6832\n",
      "Epoch: 005, AUC: 0.6356, AP: 0.6827\n",
      "Epoch: 006, AUC: 0.6340, AP: 0.6823\n",
      "Epoch: 007, AUC: 0.6329, AP: 0.6825\n",
      "Epoch: 008, AUC: 0.6318, AP: 0.6827\n",
      "Epoch: 009, AUC: 0.6315, AP: 0.6835\n",
      "Epoch: 010, AUC: 0.6311, AP: 0.6845\n",
      "Epoch: 011, AUC: 0.6308, AP: 0.6852\n",
      "Epoch: 012, AUC: 0.6309, AP: 0.6865\n",
      "Epoch: 013, AUC: 0.6312, AP: 0.6881\n",
      "Epoch: 014, AUC: 0.6313, AP: 0.6898\n",
      "Epoch: 015, AUC: 0.6310, AP: 0.6913\n",
      "Epoch: 016, AUC: 0.6310, AP: 0.6929\n",
      "Epoch: 017, AUC: 0.6307, AP: 0.6938\n",
      "Epoch: 018, AUC: 0.6310, AP: 0.6954\n",
      "Epoch: 019, AUC: 0.6305, AP: 0.6962\n",
      "Epoch: 020, AUC: 0.6301, AP: 0.6969\n",
      "Epoch: 021, AUC: 0.6304, AP: 0.6976\n",
      "Epoch: 022, AUC: 0.6302, AP: 0.6979\n",
      "Epoch: 023, AUC: 0.6301, AP: 0.6985\n",
      "Epoch: 024, AUC: 0.6300, AP: 0.6989\n",
      "Epoch: 025, AUC: 0.6300, AP: 0.6994\n",
      "Epoch: 026, AUC: 0.6298, AP: 0.6996\n",
      "Epoch: 027, AUC: 0.6302, AP: 0.7001\n",
      "Epoch: 028, AUC: 0.6307, AP: 0.7006\n",
      "Epoch: 029, AUC: 0.6313, AP: 0.7020\n",
      "Epoch: 030, AUC: 0.6326, AP: 0.7032\n",
      "Epoch: 031, AUC: 0.6347, AP: 0.7041\n",
      "Epoch: 032, AUC: 0.6372, AP: 0.7056\n",
      "Epoch: 033, AUC: 0.6403, AP: 0.7076\n",
      "Epoch: 034, AUC: 0.6453, AP: 0.7101\n",
      "Epoch: 035, AUC: 0.6525, AP: 0.7134\n",
      "Epoch: 036, AUC: 0.6614, AP: 0.7169\n",
      "Epoch: 037, AUC: 0.6711, AP: 0.7209\n",
      "Epoch: 038, AUC: 0.6778, AP: 0.7237\n",
      "Epoch: 039, AUC: 0.6826, AP: 0.7260\n",
      "Epoch: 040, AUC: 0.6872, AP: 0.7283\n",
      "Epoch: 041, AUC: 0.6923, AP: 0.7306\n",
      "Epoch: 042, AUC: 0.6983, AP: 0.7335\n",
      "Epoch: 043, AUC: 0.7065, AP: 0.7377\n",
      "Epoch: 044, AUC: 0.7178, AP: 0.7433\n",
      "Epoch: 045, AUC: 0.7288, AP: 0.7493\n",
      "Epoch: 046, AUC: 0.7400, AP: 0.7554\n",
      "Epoch: 047, AUC: 0.7508, AP: 0.7617\n",
      "Epoch: 048, AUC: 0.7587, AP: 0.7666\n",
      "Epoch: 049, AUC: 0.7644, AP: 0.7701\n",
      "Epoch: 050, AUC: 0.7690, AP: 0.7732\n",
      "Epoch: 051, AUC: 0.7719, AP: 0.7751\n",
      "Epoch: 052, AUC: 0.7745, AP: 0.7769\n",
      "Epoch: 053, AUC: 0.7773, AP: 0.7787\n",
      "Epoch: 054, AUC: 0.7790, AP: 0.7800\n",
      "Epoch: 055, AUC: 0.7811, AP: 0.7813\n",
      "Epoch: 056, AUC: 0.7827, AP: 0.7827\n",
      "Epoch: 057, AUC: 0.7842, AP: 0.7841\n",
      "Epoch: 058, AUC: 0.7853, AP: 0.7853\n",
      "Epoch: 059, AUC: 0.7860, AP: 0.7860\n",
      "Epoch: 060, AUC: 0.7863, AP: 0.7862\n",
      "Epoch: 061, AUC: 0.7869, AP: 0.7866\n",
      "Epoch: 062, AUC: 0.7874, AP: 0.7870\n",
      "Epoch: 063, AUC: 0.7878, AP: 0.7874\n",
      "Epoch: 064, AUC: 0.7880, AP: 0.7875\n",
      "Epoch: 065, AUC: 0.7876, AP: 0.7870\n",
      "Epoch: 066, AUC: 0.7872, AP: 0.7863\n",
      "Epoch: 067, AUC: 0.7872, AP: 0.7861\n",
      "Epoch: 068, AUC: 0.7886, AP: 0.7875\n",
      "Epoch: 069, AUC: 0.7893, AP: 0.7877\n",
      "Epoch: 070, AUC: 0.7897, AP: 0.7879\n",
      "Epoch: 071, AUC: 0.7897, AP: 0.7878\n",
      "Epoch: 072, AUC: 0.7890, AP: 0.7869\n",
      "Epoch: 073, AUC: 0.7882, AP: 0.7862\n",
      "Epoch: 074, AUC: 0.7881, AP: 0.7861\n",
      "Epoch: 075, AUC: 0.7892, AP: 0.7871\n",
      "Epoch: 076, AUC: 0.7903, AP: 0.7878\n",
      "Epoch: 077, AUC: 0.7909, AP: 0.7881\n",
      "Epoch: 078, AUC: 0.7911, AP: 0.7881\n",
      "Epoch: 079, AUC: 0.7907, AP: 0.7878\n",
      "Epoch: 080, AUC: 0.7900, AP: 0.7872\n",
      "Epoch: 081, AUC: 0.7890, AP: 0.7863\n",
      "Epoch: 082, AUC: 0.7898, AP: 0.7865\n",
      "Epoch: 083, AUC: 0.7908, AP: 0.7873\n",
      "Epoch: 084, AUC: 0.7911, AP: 0.7872\n",
      "Epoch: 085, AUC: 0.7912, AP: 0.7873\n",
      "Epoch: 086, AUC: 0.7909, AP: 0.7868\n",
      "Epoch: 087, AUC: 0.7905, AP: 0.7865\n",
      "Epoch: 088, AUC: 0.7901, AP: 0.7861\n",
      "Epoch: 089, AUC: 0.7899, AP: 0.7858\n",
      "Epoch: 090, AUC: 0.7902, AP: 0.7859\n",
      "Epoch: 091, AUC: 0.7905, AP: 0.7861\n",
      "Epoch: 092, AUC: 0.7909, AP: 0.7863\n",
      "Epoch: 093, AUC: 0.7907, AP: 0.7862\n",
      "Epoch: 094, AUC: 0.7906, AP: 0.7859\n",
      "Epoch: 095, AUC: 0.7902, AP: 0.7856\n",
      "Epoch: 096, AUC: 0.7894, AP: 0.7849\n",
      "Epoch: 097, AUC: 0.7891, AP: 0.7847\n",
      "Epoch: 098, AUC: 0.7895, AP: 0.7851\n",
      "Epoch: 099, AUC: 0.7897, AP: 0.7852\n",
      "Epoch: 100, AUC: 0.7898, AP: 0.7851\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e303db39-6b47-4273-8dc4-2b3460ff445d",
   "metadata": {},
   "source": [
    "### Use Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cd76109-1a7b-48b7-ae8a-fcc526fe682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "967ada24-4636-4856-bf38-40d5efd02fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "out_channels = 3\n",
    "num_features = dataset.num_features\n",
    "epochs = 100\n",
    "\n",
    "# model\n",
    "model = GAE(GCNEncoder(num_features, out_channels))\n",
    "\n",
    "# move to GPU (if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "\n",
    "# inizialize the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d08f8c50-76b1-4316-be68-9de5cf746b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/GAE1_experiment_'+'3d_100_epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38cafbc4-60b9-43fa-8e51-7e0f2a55cf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.6514, AP: 0.6807\n",
      "Epoch: 002, AUC: 0.6374, AP: 0.6756\n",
      "Epoch: 003, AUC: 0.6315, AP: 0.6752\n",
      "Epoch: 004, AUC: 0.6319, AP: 0.6782\n",
      "Epoch: 005, AUC: 0.6332, AP: 0.6818\n",
      "Epoch: 006, AUC: 0.6318, AP: 0.6820\n",
      "Epoch: 007, AUC: 0.6300, AP: 0.6820\n",
      "Epoch: 008, AUC: 0.6301, AP: 0.6831\n",
      "Epoch: 009, AUC: 0.6307, AP: 0.6849\n",
      "Epoch: 010, AUC: 0.6315, AP: 0.6863\n",
      "Epoch: 011, AUC: 0.6321, AP: 0.6882\n",
      "Epoch: 012, AUC: 0.6322, AP: 0.6897\n",
      "Epoch: 013, AUC: 0.6323, AP: 0.6917\n",
      "Epoch: 014, AUC: 0.6324, AP: 0.6937\n",
      "Epoch: 015, AUC: 0.6330, AP: 0.6953\n",
      "Epoch: 016, AUC: 0.6339, AP: 0.6972\n",
      "Epoch: 017, AUC: 0.6346, AP: 0.6989\n",
      "Epoch: 018, AUC: 0.6352, AP: 0.7005\n",
      "Epoch: 019, AUC: 0.6355, AP: 0.7021\n",
      "Epoch: 020, AUC: 0.6358, AP: 0.7028\n",
      "Epoch: 021, AUC: 0.6358, AP: 0.7040\n",
      "Epoch: 022, AUC: 0.6359, AP: 0.7045\n",
      "Epoch: 023, AUC: 0.6363, AP: 0.7051\n",
      "Epoch: 024, AUC: 0.6371, AP: 0.7061\n",
      "Epoch: 025, AUC: 0.6394, AP: 0.7075\n",
      "Epoch: 026, AUC: 0.6432, AP: 0.7097\n",
      "Epoch: 027, AUC: 0.6508, AP: 0.7131\n",
      "Epoch: 028, AUC: 0.6630, AP: 0.7183\n",
      "Epoch: 029, AUC: 0.6761, AP: 0.7236\n",
      "Epoch: 030, AUC: 0.6892, AP: 0.7295\n",
      "Epoch: 031, AUC: 0.7007, AP: 0.7350\n",
      "Epoch: 032, AUC: 0.7116, AP: 0.7404\n",
      "Epoch: 033, AUC: 0.7227, AP: 0.7459\n",
      "Epoch: 034, AUC: 0.7328, AP: 0.7513\n",
      "Epoch: 035, AUC: 0.7447, AP: 0.7578\n",
      "Epoch: 036, AUC: 0.7574, AP: 0.7654\n",
      "Epoch: 037, AUC: 0.7661, AP: 0.7712\n",
      "Epoch: 038, AUC: 0.7726, AP: 0.7756\n",
      "Epoch: 039, AUC: 0.7771, AP: 0.7787\n",
      "Epoch: 040, AUC: 0.7795, AP: 0.7805\n",
      "Epoch: 041, AUC: 0.7816, AP: 0.7823\n",
      "Epoch: 042, AUC: 0.7828, AP: 0.7832\n",
      "Epoch: 043, AUC: 0.7840, AP: 0.7841\n",
      "Epoch: 044, AUC: 0.7850, AP: 0.7849\n",
      "Epoch: 045, AUC: 0.7862, AP: 0.7858\n",
      "Epoch: 046, AUC: 0.7859, AP: 0.7856\n",
      "Epoch: 047, AUC: 0.7863, AP: 0.7860\n",
      "Epoch: 048, AUC: 0.7871, AP: 0.7866\n",
      "Epoch: 049, AUC: 0.7876, AP: 0.7870\n",
      "Epoch: 050, AUC: 0.7880, AP: 0.7874\n",
      "Epoch: 051, AUC: 0.7882, AP: 0.7876\n",
      "Epoch: 052, AUC: 0.7885, AP: 0.7879\n",
      "Epoch: 053, AUC: 0.7892, AP: 0.7884\n",
      "Epoch: 054, AUC: 0.7893, AP: 0.7881\n",
      "Epoch: 055, AUC: 0.7890, AP: 0.7878\n",
      "Epoch: 056, AUC: 0.7894, AP: 0.7878\n",
      "Epoch: 057, AUC: 0.7907, AP: 0.7885\n",
      "Epoch: 058, AUC: 0.7910, AP: 0.7886\n",
      "Epoch: 059, AUC: 0.7904, AP: 0.7879\n",
      "Epoch: 060, AUC: 0.7900, AP: 0.7873\n",
      "Epoch: 061, AUC: 0.7908, AP: 0.7879\n",
      "Epoch: 062, AUC: 0.7918, AP: 0.7882\n",
      "Epoch: 063, AUC: 0.7919, AP: 0.7879\n",
      "Epoch: 064, AUC: 0.7916, AP: 0.7877\n",
      "Epoch: 065, AUC: 0.7918, AP: 0.7875\n",
      "Epoch: 066, AUC: 0.7911, AP: 0.7868\n",
      "Epoch: 067, AUC: 0.7913, AP: 0.7867\n",
      "Epoch: 068, AUC: 0.7910, AP: 0.7863\n",
      "Epoch: 069, AUC: 0.7907, AP: 0.7857\n",
      "Epoch: 070, AUC: 0.7909, AP: 0.7856\n",
      "Epoch: 071, AUC: 0.7922, AP: 0.7861\n",
      "Epoch: 072, AUC: 0.7927, AP: 0.7864\n",
      "Epoch: 073, AUC: 0.7919, AP: 0.7857\n",
      "Epoch: 074, AUC: 0.7908, AP: 0.7851\n",
      "Epoch: 075, AUC: 0.7904, AP: 0.7846\n",
      "Epoch: 076, AUC: 0.7916, AP: 0.7852\n",
      "Epoch: 077, AUC: 0.7929, AP: 0.7863\n",
      "Epoch: 078, AUC: 0.7929, AP: 0.7860\n",
      "Epoch: 079, AUC: 0.7926, AP: 0.7860\n",
      "Epoch: 080, AUC: 0.7915, AP: 0.7854\n",
      "Epoch: 081, AUC: 0.7909, AP: 0.7853\n",
      "Epoch: 082, AUC: 0.7914, AP: 0.7856\n",
      "Epoch: 083, AUC: 0.7927, AP: 0.7862\n",
      "Epoch: 084, AUC: 0.7933, AP: 0.7866\n",
      "Epoch: 085, AUC: 0.7930, AP: 0.7863\n",
      "Epoch: 086, AUC: 0.7914, AP: 0.7855\n",
      "Epoch: 087, AUC: 0.7901, AP: 0.7846\n",
      "Epoch: 088, AUC: 0.7900, AP: 0.7844\n",
      "Epoch: 089, AUC: 0.7918, AP: 0.7855\n",
      "Epoch: 090, AUC: 0.7925, AP: 0.7853\n",
      "Epoch: 091, AUC: 0.7921, AP: 0.7850\n",
      "Epoch: 092, AUC: 0.7909, AP: 0.7846\n",
      "Epoch: 093, AUC: 0.7902, AP: 0.7842\n",
      "Epoch: 094, AUC: 0.7899, AP: 0.7842\n",
      "Epoch: 095, AUC: 0.7902, AP: 0.7842\n",
      "Epoch: 096, AUC: 0.7916, AP: 0.7848\n",
      "Epoch: 097, AUC: 0.7919, AP: 0.7846\n",
      "Epoch: 098, AUC: 0.7918, AP: 0.7844\n",
      "Epoch: 099, AUC: 0.7913, AP: 0.7842\n",
      "Epoch: 100, AUC: 0.7904, AP: 0.7837\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('auc train',auc,epoch) # new line\n",
    "    writer.add_scalar('ap train',ap,epoch)   # new line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9494d8-6a6a-4fd2-bd65-59d16533b64d",
   "metadata": {},
   "source": [
    "# Graph Variational AutoEncoder (GVAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49c4ecd2-c673-4f48-9612-e37be58f6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import VGAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0737703b-7c8d-4b1f-9728-7de1595c4e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Travail\\anaconda3\\envs\\pyg\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "dataset = Planetoid(\"\\..\", \"CiteSeer\", transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "data.train_mask = data.val_mask = data.test_mask = data.y = None\n",
    "data = train_test_split_edges(data)\n",
    "\n",
    "\n",
    "class VariationalGCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(VariationalGCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True) # cached only for transductive learning\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d54bd97a-aae3-4ea3-bcde-7e26e7b0dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_channels = 2\n",
    "num_features = dataset.num_features\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "model = VGAE(VariationalGCNEncoder(num_features, out_channels))  # new line\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = data.x.to(device)\n",
    "train_pos_edge_index = data.train_pos_edge_index.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9b1797a-44db-485b-9fa0-a44bdc315060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(x, train_pos_edge_index)\n",
    "    loss = model.recon_loss(z, train_pos_edge_index)\n",
    "    \n",
    "    loss = loss + (1 / data.num_nodes) * model.kl_loss()  # new line\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "def test(pos_edge_index, neg_edge_index):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x, train_pos_edge_index)\n",
    "    return model.test(z, pos_edge_index, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd69ca14-a06e-422e-8b7f-f45bf10f56b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, AUC: 0.5810, AP: 0.5937\n",
      "Epoch: 002, AUC: 0.5848, AP: 0.6051\n",
      "Epoch: 003, AUC: 0.5925, AP: 0.6193\n",
      "Epoch: 004, AUC: 0.5911, AP: 0.6188\n",
      "Epoch: 005, AUC: 0.5947, AP: 0.6212\n",
      "Epoch: 006, AUC: 0.5976, AP: 0.6243\n",
      "Epoch: 007, AUC: 0.5999, AP: 0.6267\n",
      "Epoch: 008, AUC: 0.6009, AP: 0.6278\n",
      "Epoch: 009, AUC: 0.6027, AP: 0.6291\n",
      "Epoch: 010, AUC: 0.6041, AP: 0.6302\n",
      "Epoch: 011, AUC: 0.6044, AP: 0.6304\n",
      "Epoch: 012, AUC: 0.6050, AP: 0.6311\n",
      "Epoch: 013, AUC: 0.6049, AP: 0.6313\n",
      "Epoch: 014, AUC: 0.6042, AP: 0.6309\n",
      "Epoch: 015, AUC: 0.6038, AP: 0.6312\n",
      "Epoch: 016, AUC: 0.6032, AP: 0.6314\n",
      "Epoch: 017, AUC: 0.6025, AP: 0.6312\n",
      "Epoch: 018, AUC: 0.6016, AP: 0.6310\n",
      "Epoch: 019, AUC: 0.5994, AP: 0.6294\n",
      "Epoch: 020, AUC: 0.5959, AP: 0.6282\n",
      "Epoch: 021, AUC: 0.5960, AP: 0.6286\n",
      "Epoch: 022, AUC: 0.5992, AP: 0.6306\n",
      "Epoch: 023, AUC: 0.6041, AP: 0.6341\n",
      "Epoch: 024, AUC: 0.6081, AP: 0.6371\n",
      "Epoch: 025, AUC: 0.6110, AP: 0.6391\n",
      "Epoch: 026, AUC: 0.6142, AP: 0.6409\n",
      "Epoch: 027, AUC: 0.6168, AP: 0.6424\n",
      "Epoch: 028, AUC: 0.6192, AP: 0.6446\n",
      "Epoch: 029, AUC: 0.6207, AP: 0.6458\n",
      "Epoch: 030, AUC: 0.6222, AP: 0.6469\n",
      "Epoch: 031, AUC: 0.6236, AP: 0.6479\n",
      "Epoch: 032, AUC: 0.6251, AP: 0.6490\n",
      "Epoch: 033, AUC: 0.6264, AP: 0.6502\n",
      "Epoch: 034, AUC: 0.6276, AP: 0.6508\n",
      "Epoch: 035, AUC: 0.6289, AP: 0.6520\n",
      "Epoch: 036, AUC: 0.6303, AP: 0.6533\n",
      "Epoch: 037, AUC: 0.6312, AP: 0.6542\n",
      "Epoch: 038, AUC: 0.6324, AP: 0.6555\n",
      "Epoch: 039, AUC: 0.6335, AP: 0.6568\n",
      "Epoch: 040, AUC: 0.6345, AP: 0.6579\n",
      "Epoch: 041, AUC: 0.6357, AP: 0.6597\n",
      "Epoch: 042, AUC: 0.6365, AP: 0.6609\n",
      "Epoch: 043, AUC: 0.6378, AP: 0.6626\n",
      "Epoch: 044, AUC: 0.6390, AP: 0.6644\n",
      "Epoch: 045, AUC: 0.6400, AP: 0.6660\n",
      "Epoch: 046, AUC: 0.6409, AP: 0.6676\n",
      "Epoch: 047, AUC: 0.6420, AP: 0.6693\n",
      "Epoch: 048, AUC: 0.6429, AP: 0.6709\n",
      "Epoch: 049, AUC: 0.6437, AP: 0.6727\n",
      "Epoch: 050, AUC: 0.6444, AP: 0.6745\n",
      "Epoch: 051, AUC: 0.6448, AP: 0.6759\n",
      "Epoch: 052, AUC: 0.6453, AP: 0.6774\n",
      "Epoch: 053, AUC: 0.6455, AP: 0.6786\n",
      "Epoch: 054, AUC: 0.6458, AP: 0.6799\n",
      "Epoch: 055, AUC: 0.6457, AP: 0.6806\n",
      "Epoch: 056, AUC: 0.6457, AP: 0.6815\n",
      "Epoch: 057, AUC: 0.6460, AP: 0.6832\n",
      "Epoch: 058, AUC: 0.6458, AP: 0.6839\n",
      "Epoch: 059, AUC: 0.6458, AP: 0.6852\n",
      "Epoch: 060, AUC: 0.6456, AP: 0.6866\n",
      "Epoch: 061, AUC: 0.6454, AP: 0.6880\n",
      "Epoch: 062, AUC: 0.6453, AP: 0.6894\n",
      "Epoch: 063, AUC: 0.6456, AP: 0.6912\n",
      "Epoch: 064, AUC: 0.6455, AP: 0.6924\n",
      "Epoch: 065, AUC: 0.6453, AP: 0.6936\n",
      "Epoch: 066, AUC: 0.6452, AP: 0.6947\n",
      "Epoch: 067, AUC: 0.6449, AP: 0.6956\n",
      "Epoch: 068, AUC: 0.6448, AP: 0.6967\n",
      "Epoch: 069, AUC: 0.6448, AP: 0.6981\n",
      "Epoch: 070, AUC: 0.6449, AP: 0.6991\n",
      "Epoch: 071, AUC: 0.6449, AP: 0.7000\n",
      "Epoch: 072, AUC: 0.6450, AP: 0.7009\n",
      "Epoch: 073, AUC: 0.6452, AP: 0.7015\n",
      "Epoch: 074, AUC: 0.6456, AP: 0.7024\n",
      "Epoch: 075, AUC: 0.6461, AP: 0.7033\n",
      "Epoch: 076, AUC: 0.6469, AP: 0.7044\n",
      "Epoch: 077, AUC: 0.6483, AP: 0.7055\n",
      "Epoch: 078, AUC: 0.6504, AP: 0.7068\n",
      "Epoch: 079, AUC: 0.6527, AP: 0.7082\n",
      "Epoch: 080, AUC: 0.6556, AP: 0.7101\n",
      "Epoch: 081, AUC: 0.6585, AP: 0.7120\n",
      "Epoch: 082, AUC: 0.6618, AP: 0.7140\n",
      "Epoch: 083, AUC: 0.6656, AP: 0.7158\n",
      "Epoch: 084, AUC: 0.6704, AP: 0.7182\n",
      "Epoch: 085, AUC: 0.6757, AP: 0.7211\n",
      "Epoch: 086, AUC: 0.6795, AP: 0.7231\n",
      "Epoch: 087, AUC: 0.6831, AP: 0.7253\n",
      "Epoch: 088, AUC: 0.6873, AP: 0.7275\n",
      "Epoch: 089, AUC: 0.6920, AP: 0.7301\n",
      "Epoch: 090, AUC: 0.6978, AP: 0.7332\n",
      "Epoch: 091, AUC: 0.7029, AP: 0.7357\n",
      "Epoch: 092, AUC: 0.7081, AP: 0.7386\n",
      "Epoch: 093, AUC: 0.7128, AP: 0.7413\n",
      "Epoch: 094, AUC: 0.7175, AP: 0.7442\n",
      "Epoch: 095, AUC: 0.7227, AP: 0.7474\n",
      "Epoch: 096, AUC: 0.7287, AP: 0.7508\n",
      "Epoch: 097, AUC: 0.7337, AP: 0.7538\n",
      "Epoch: 098, AUC: 0.7386, AP: 0.7571\n",
      "Epoch: 099, AUC: 0.7433, AP: 0.7602\n",
      "Epoch: 100, AUC: 0.7478, AP: 0.7630\n",
      "Epoch: 101, AUC: 0.7515, AP: 0.7655\n",
      "Epoch: 102, AUC: 0.7556, AP: 0.7684\n",
      "Epoch: 103, AUC: 0.7588, AP: 0.7709\n",
      "Epoch: 104, AUC: 0.7619, AP: 0.7731\n",
      "Epoch: 105, AUC: 0.7645, AP: 0.7749\n",
      "Epoch: 106, AUC: 0.7664, AP: 0.7764\n",
      "Epoch: 107, AUC: 0.7681, AP: 0.7777\n",
      "Epoch: 108, AUC: 0.7699, AP: 0.7792\n",
      "Epoch: 109, AUC: 0.7722, AP: 0.7809\n",
      "Epoch: 110, AUC: 0.7737, AP: 0.7821\n",
      "Epoch: 111, AUC: 0.7750, AP: 0.7829\n",
      "Epoch: 112, AUC: 0.7757, AP: 0.7834\n",
      "Epoch: 113, AUC: 0.7772, AP: 0.7846\n",
      "Epoch: 114, AUC: 0.7786, AP: 0.7857\n",
      "Epoch: 115, AUC: 0.7796, AP: 0.7866\n",
      "Epoch: 116, AUC: 0.7806, AP: 0.7873\n",
      "Epoch: 117, AUC: 0.7814, AP: 0.7877\n",
      "Epoch: 118, AUC: 0.7821, AP: 0.7881\n",
      "Epoch: 119, AUC: 0.7828, AP: 0.7883\n",
      "Epoch: 120, AUC: 0.7837, AP: 0.7892\n",
      "Epoch: 121, AUC: 0.7843, AP: 0.7894\n",
      "Epoch: 122, AUC: 0.7850, AP: 0.7899\n",
      "Epoch: 123, AUC: 0.7857, AP: 0.7901\n",
      "Epoch: 124, AUC: 0.7860, AP: 0.7901\n",
      "Epoch: 125, AUC: 0.7863, AP: 0.7901\n",
      "Epoch: 126, AUC: 0.7869, AP: 0.7905\n",
      "Epoch: 127, AUC: 0.7873, AP: 0.7908\n",
      "Epoch: 128, AUC: 0.7876, AP: 0.7909\n",
      "Epoch: 129, AUC: 0.7881, AP: 0.7911\n",
      "Epoch: 130, AUC: 0.7884, AP: 0.7911\n",
      "Epoch: 131, AUC: 0.7886, AP: 0.7912\n",
      "Epoch: 132, AUC: 0.7888, AP: 0.7913\n",
      "Epoch: 133, AUC: 0.7894, AP: 0.7919\n",
      "Epoch: 134, AUC: 0.7897, AP: 0.7921\n",
      "Epoch: 135, AUC: 0.7901, AP: 0.7922\n",
      "Epoch: 136, AUC: 0.7905, AP: 0.7923\n",
      "Epoch: 137, AUC: 0.7904, AP: 0.7922\n",
      "Epoch: 138, AUC: 0.7907, AP: 0.7923\n",
      "Epoch: 139, AUC: 0.7909, AP: 0.7924\n",
      "Epoch: 140, AUC: 0.7910, AP: 0.7926\n",
      "Epoch: 141, AUC: 0.7913, AP: 0.7925\n",
      "Epoch: 142, AUC: 0.7914, AP: 0.7925\n",
      "Epoch: 143, AUC: 0.7914, AP: 0.7922\n",
      "Epoch: 144, AUC: 0.7918, AP: 0.7925\n",
      "Epoch: 145, AUC: 0.7920, AP: 0.7927\n",
      "Epoch: 146, AUC: 0.7920, AP: 0.7929\n",
      "Epoch: 147, AUC: 0.7920, AP: 0.7926\n",
      "Epoch: 148, AUC: 0.7922, AP: 0.7926\n",
      "Epoch: 149, AUC: 0.7923, AP: 0.7926\n",
      "Epoch: 150, AUC: 0.7922, AP: 0.7922\n",
      "Epoch: 151, AUC: 0.7921, AP: 0.7922\n",
      "Epoch: 152, AUC: 0.7922, AP: 0.7921\n",
      "Epoch: 153, AUC: 0.7925, AP: 0.7923\n",
      "Epoch: 154, AUC: 0.7926, AP: 0.7924\n",
      "Epoch: 155, AUC: 0.7925, AP: 0.7921\n",
      "Epoch: 156, AUC: 0.7926, AP: 0.7922\n",
      "Epoch: 157, AUC: 0.7926, AP: 0.7922\n",
      "Epoch: 158, AUC: 0.7925, AP: 0.7923\n",
      "Epoch: 159, AUC: 0.7925, AP: 0.7924\n",
      "Epoch: 160, AUC: 0.7926, AP: 0.7922\n",
      "Epoch: 161, AUC: 0.7928, AP: 0.7924\n",
      "Epoch: 162, AUC: 0.7929, AP: 0.7924\n",
      "Epoch: 163, AUC: 0.7928, AP: 0.7923\n",
      "Epoch: 164, AUC: 0.7929, AP: 0.7924\n",
      "Epoch: 165, AUC: 0.7929, AP: 0.7924\n",
      "Epoch: 166, AUC: 0.7927, AP: 0.7923\n",
      "Epoch: 167, AUC: 0.7926, AP: 0.7920\n",
      "Epoch: 168, AUC: 0.7925, AP: 0.7920\n",
      "Epoch: 169, AUC: 0.7930, AP: 0.7924\n",
      "Epoch: 170, AUC: 0.7930, AP: 0.7923\n",
      "Epoch: 171, AUC: 0.7928, AP: 0.7922\n",
      "Epoch: 172, AUC: 0.7929, AP: 0.7923\n",
      "Epoch: 173, AUC: 0.7929, AP: 0.7922\n",
      "Epoch: 174, AUC: 0.7927, AP: 0.7918\n",
      "Epoch: 175, AUC: 0.7926, AP: 0.7918\n",
      "Epoch: 176, AUC: 0.7930, AP: 0.7920\n",
      "Epoch: 177, AUC: 0.7931, AP: 0.7921\n",
      "Epoch: 178, AUC: 0.7931, AP: 0.7921\n",
      "Epoch: 179, AUC: 0.7930, AP: 0.7920\n",
      "Epoch: 180, AUC: 0.7928, AP: 0.7918\n",
      "Epoch: 181, AUC: 0.7925, AP: 0.7913\n",
      "Epoch: 182, AUC: 0.7923, AP: 0.7910\n",
      "Epoch: 183, AUC: 0.7923, AP: 0.7912\n",
      "Epoch: 184, AUC: 0.7924, AP: 0.7914\n",
      "Epoch: 185, AUC: 0.7922, AP: 0.7913\n",
      "Epoch: 186, AUC: 0.7920, AP: 0.7911\n",
      "Epoch: 187, AUC: 0.7918, AP: 0.7908\n",
      "Epoch: 188, AUC: 0.7914, AP: 0.7903\n",
      "Epoch: 189, AUC: 0.7913, AP: 0.7900\n",
      "Epoch: 190, AUC: 0.7912, AP: 0.7899\n",
      "Epoch: 191, AUC: 0.7912, AP: 0.7900\n",
      "Epoch: 192, AUC: 0.7911, AP: 0.7899\n",
      "Epoch: 193, AUC: 0.7911, AP: 0.7899\n",
      "Epoch: 194, AUC: 0.7908, AP: 0.7894\n",
      "Epoch: 195, AUC: 0.7904, AP: 0.7888\n",
      "Epoch: 196, AUC: 0.7901, AP: 0.7884\n",
      "Epoch: 197, AUC: 0.7900, AP: 0.7883\n",
      "Epoch: 198, AUC: 0.7899, AP: 0.7882\n",
      "Epoch: 199, AUC: 0.7897, AP: 0.7881\n",
      "Epoch: 200, AUC: 0.7895, AP: 0.7880\n",
      "Epoch: 201, AUC: 0.7894, AP: 0.7880\n",
      "Epoch: 202, AUC: 0.7893, AP: 0.7878\n",
      "Epoch: 203, AUC: 0.7891, AP: 0.7876\n",
      "Epoch: 204, AUC: 0.7889, AP: 0.7875\n",
      "Epoch: 205, AUC: 0.7885, AP: 0.7870\n",
      "Epoch: 206, AUC: 0.7882, AP: 0.7868\n",
      "Epoch: 207, AUC: 0.7879, AP: 0.7864\n",
      "Epoch: 208, AUC: 0.7877, AP: 0.7863\n",
      "Epoch: 209, AUC: 0.7876, AP: 0.7863\n",
      "Epoch: 210, AUC: 0.7876, AP: 0.7863\n",
      "Epoch: 211, AUC: 0.7874, AP: 0.7861\n",
      "Epoch: 212, AUC: 0.7869, AP: 0.7857\n",
      "Epoch: 213, AUC: 0.7866, AP: 0.7855\n",
      "Epoch: 214, AUC: 0.7866, AP: 0.7857\n",
      "Epoch: 215, AUC: 0.7866, AP: 0.7857\n",
      "Epoch: 216, AUC: 0.7868, AP: 0.7859\n",
      "Epoch: 217, AUC: 0.7865, AP: 0.7855\n",
      "Epoch: 218, AUC: 0.7863, AP: 0.7854\n",
      "Epoch: 219, AUC: 0.7861, AP: 0.7854\n",
      "Epoch: 220, AUC: 0.7860, AP: 0.7853\n",
      "Epoch: 221, AUC: 0.7858, AP: 0.7851\n",
      "Epoch: 222, AUC: 0.7857, AP: 0.7853\n",
      "Epoch: 223, AUC: 0.7856, AP: 0.7852\n",
      "Epoch: 224, AUC: 0.7853, AP: 0.7848\n",
      "Epoch: 225, AUC: 0.7852, AP: 0.7846\n",
      "Epoch: 226, AUC: 0.7849, AP: 0.7845\n",
      "Epoch: 227, AUC: 0.7846, AP: 0.7843\n",
      "Epoch: 228, AUC: 0.7845, AP: 0.7842\n",
      "Epoch: 229, AUC: 0.7847, AP: 0.7845\n",
      "Epoch: 230, AUC: 0.7846, AP: 0.7844\n",
      "Epoch: 231, AUC: 0.7842, AP: 0.7842\n",
      "Epoch: 232, AUC: 0.7842, AP: 0.7842\n",
      "Epoch: 233, AUC: 0.7840, AP: 0.7841\n",
      "Epoch: 234, AUC: 0.7841, AP: 0.7842\n",
      "Epoch: 235, AUC: 0.7841, AP: 0.7841\n",
      "Epoch: 236, AUC: 0.7839, AP: 0.7841\n",
      "Epoch: 237, AUC: 0.7837, AP: 0.7839\n",
      "Epoch: 238, AUC: 0.7836, AP: 0.7838\n",
      "Epoch: 239, AUC: 0.7836, AP: 0.7836\n",
      "Epoch: 240, AUC: 0.7835, AP: 0.7837\n",
      "Epoch: 241, AUC: 0.7837, AP: 0.7840\n",
      "Epoch: 242, AUC: 0.7835, AP: 0.7837\n",
      "Epoch: 243, AUC: 0.7833, AP: 0.7837\n",
      "Epoch: 244, AUC: 0.7832, AP: 0.7836\n",
      "Epoch: 245, AUC: 0.7831, AP: 0.7837\n",
      "Epoch: 246, AUC: 0.7831, AP: 0.7836\n",
      "Epoch: 247, AUC: 0.7831, AP: 0.7836\n",
      "Epoch: 248, AUC: 0.7833, AP: 0.7838\n",
      "Epoch: 249, AUC: 0.7833, AP: 0.7838\n",
      "Epoch: 250, AUC: 0.7830, AP: 0.7838\n",
      "Epoch: 251, AUC: 0.7827, AP: 0.7835\n",
      "Epoch: 252, AUC: 0.7825, AP: 0.7833\n",
      "Epoch: 253, AUC: 0.7826, AP: 0.7831\n",
      "Epoch: 254, AUC: 0.7823, AP: 0.7831\n",
      "Epoch: 255, AUC: 0.7824, AP: 0.7832\n",
      "Epoch: 256, AUC: 0.7823, AP: 0.7832\n",
      "Epoch: 257, AUC: 0.7826, AP: 0.7835\n",
      "Epoch: 258, AUC: 0.7826, AP: 0.7834\n",
      "Epoch: 259, AUC: 0.7824, AP: 0.7832\n",
      "Epoch: 260, AUC: 0.7821, AP: 0.7829\n",
      "Epoch: 261, AUC: 0.7815, AP: 0.7822\n",
      "Epoch: 262, AUC: 0.7814, AP: 0.7822\n",
      "Epoch: 263, AUC: 0.7820, AP: 0.7828\n",
      "Epoch: 264, AUC: 0.7821, AP: 0.7828\n",
      "Epoch: 265, AUC: 0.7821, AP: 0.7828\n",
      "Epoch: 266, AUC: 0.7818, AP: 0.7828\n",
      "Epoch: 267, AUC: 0.7812, AP: 0.7823\n",
      "Epoch: 268, AUC: 0.7812, AP: 0.7824\n",
      "Epoch: 269, AUC: 0.7812, AP: 0.7823\n",
      "Epoch: 270, AUC: 0.7810, AP: 0.7822\n",
      "Epoch: 271, AUC: 0.7810, AP: 0.7822\n",
      "Epoch: 272, AUC: 0.7808, AP: 0.7821\n",
      "Epoch: 273, AUC: 0.7805, AP: 0.7820\n",
      "Epoch: 274, AUC: 0.7798, AP: 0.7813\n",
      "Epoch: 275, AUC: 0.7798, AP: 0.7813\n",
      "Epoch: 276, AUC: 0.7802, AP: 0.7818\n",
      "Epoch: 277, AUC: 0.7801, AP: 0.7819\n",
      "Epoch: 278, AUC: 0.7798, AP: 0.7816\n",
      "Epoch: 279, AUC: 0.7792, AP: 0.7810\n",
      "Epoch: 280, AUC: 0.7787, AP: 0.7803\n",
      "Epoch: 281, AUC: 0.7786, AP: 0.7804\n",
      "Epoch: 282, AUC: 0.7787, AP: 0.7807\n",
      "Epoch: 283, AUC: 0.7788, AP: 0.7808\n",
      "Epoch: 284, AUC: 0.7782, AP: 0.7803\n",
      "Epoch: 285, AUC: 0.7782, AP: 0.7804\n",
      "Epoch: 286, AUC: 0.7781, AP: 0.7801\n",
      "Epoch: 287, AUC: 0.7779, AP: 0.7800\n",
      "Epoch: 288, AUC: 0.7775, AP: 0.7797\n",
      "Epoch: 289, AUC: 0.7773, AP: 0.7795\n",
      "Epoch: 290, AUC: 0.7770, AP: 0.7794\n",
      "Epoch: 291, AUC: 0.7764, AP: 0.7787\n",
      "Epoch: 292, AUC: 0.7765, AP: 0.7789\n",
      "Epoch: 293, AUC: 0.7767, AP: 0.7790\n",
      "Epoch: 294, AUC: 0.7768, AP: 0.7790\n",
      "Epoch: 295, AUC: 0.7767, AP: 0.7790\n",
      "Epoch: 296, AUC: 0.7761, AP: 0.7786\n",
      "Epoch: 297, AUC: 0.7761, AP: 0.7787\n",
      "Epoch: 298, AUC: 0.7760, AP: 0.7787\n",
      "Epoch: 299, AUC: 0.7765, AP: 0.7790\n",
      "Epoch: 300, AUC: 0.7766, AP: 0.7791\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/VGAE_experiment_'+'2d_300_epochs')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    auc, ap = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "    print('Epoch: {:03d}, AUC: {:.4f}, AP: {:.4f}'.format(epoch, auc, ap))\n",
    "    \n",
    "    \n",
    "    writer.add_scalar('auc train',auc,epoch) # new line\n",
    "    writer.add_scalar('ap train',ap,epoch)   # new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa52c87-6961-40b6-b830-92d93332aaac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
